{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ---\n",
        "# Title: Adjacent Possible Exploration (APE) - Scaled-Down Experiment\n",
        "# Description: This notebook implements the scaled-down experiment for the NeurIPS 2025 submission\n",
        "#              \"APE: A Data-Centric Benchmark for Efficient LLM Adaptation in Text Summarization\".\n",
        "#              It fine-tunes T5-base on 1,200 CNN/DailyMail articles over 15 iterations with 80-article batches,\n",
        "#              evaluates qualitative results on 100 test articles, and saves outputs for reproducibility.\n",
        "# Author: [Anonymous for Submission]\n",
        "# Institution: [Anonymous for Submission]\n",
        "# Date: April 10, 2025\n",
        "# License: CC BY 4.0 (Attribution for non-commercial use; anonymized for review)\n",
        "# Contact: [Anonymous email or submission portal reference]\n",
        "# Requirements: Python 3.8+, transformers>=4.28, datasets>=2.14, torch>=2.0, nltk>=3.8,\n",
        "#               rouge_score>=0.1, bert-score>=0.3, matplotlib>=3.7, seaborn>=0.12, pandas>=2.0\n",
        "# Hardware: Google Colab T4 GPU (16 GB VRAM, 7.5 TFLOPS recommended)\n",
        "# Expected Runtime: ~2-3 hours on T4 GPU\n",
        "# Overview:\n",
        "#   1. Environment Setup and Verification\n",
        "#   2. Model and Dataset Loading\n",
        "#   3. APE Perturbation and Fine-Tuning\n",
        "#   4. Qualitative Analysis and Output Saving\n",
        "# ---\n"
      ],
      "metadata": {
        "id": "31znTXO-_Qqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import core libraries for environment checks\n",
        "import sys\n",
        "import pkg_resources\n",
        "import platform\n",
        "import datetime\n",
        "import os\n",
        "from typing import List, Dict\n",
        "import warnings\n",
        "import torch\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "IUmZz8d6GV3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define required packages and minimum versions\n",
        "REQUIRED_PACKAGES = {\n",
        "    \"transformers\": \"4.28.0\",\n",
        "    \"datasets\": \"2.14.0\",\n",
        "    \"torch\": \"2.0.0\",\n",
        "    \"nltk\": \"3.8.0\",\n",
        "    \"rouge_score\": \"0.1.0\",\n",
        "    \"bert_score\": \"0.3.0\",\n",
        "    \"matplotlib\": \"3.7.0\",\n",
        "    \"seaborn\": \"0.12.0\",\n",
        "    \"pandas\": \"2.0.0\",\n",
        "    \"numpy\": \"1.23.0\"\n",
        "}\n",
        "\n",
        "def check_environment() -> bool:\n",
        "    \"\"\"Verify the Python environment meets minimum requirements.\"\"\"\n",
        "    print(\"\\n=== Environment Verification ===\")\n",
        "\n",
        "    # Check Python version\n",
        "    python_version = sys.version_info\n",
        "    if python_version < (3, 8):\n",
        "        print(f\"Error: Python {python_version.major}.{python_version.minor} detected. Requires 3.8+.\")\n",
        "        return False\n",
        "    print(f\"Python Version: {platform.python_version()} - OK\")\n",
        "\n",
        "    # Check package versions\n",
        "    for pkg, min_version in REQUIRED_PACKAGES.items():\n",
        "        try:\n",
        "            installed_version = pkg_resources.get_distribution(pkg).version\n",
        "            if pkg_resources.parse_version(installed_version) < pkg_resources.parse_version(min_version):\n",
        "                print(f\"Error: {pkg} version {installed_version} is below required {min_version}.\")\n",
        "                return False\n",
        "            print(f\"{pkg}: {installed_version} - OK\")\n",
        "        except pkg_resources.DistributionNotFound:\n",
        "            print(f\"Error: {pkg} is not installed. Install with `pip install {pkg}`.\")\n",
        "            return False\n",
        "\n",
        "    # Check GPU availability\n",
        "    if not torch.cuda.is_available():\n",
        "        print(\"Warning: No GPU detected. CPU will be used, but T4 GPU is recommended.\")\n",
        "    else:\n",
        "        gpu_name = torch.cuda.get_device_name(0)\n",
        "        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
        "        print(f\"GPU: {gpu_name} ({gpu_memory:.1f} GiB) - OK\")\n",
        "\n",
        "    # Check Google Drive connectivity\n",
        "    try:\n",
        "        drive.mount('/content/drive', force_remount=True)\n",
        "        print(\"Google Drive: Mounted successfully - OK\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error: Google Drive mount failed - {str(e)}\")\n",
        "        return False\n",
        "\n",
        "    return True\n",
        "\n",
        "# Run environment check\n",
        "if not check_environment():\n",
        "    raise SystemExit(\"Environment check failed. Please resolve issues and rerun.\")\n",
        "\n",
        "# Install missing packages (optional; uncomment if needed)\n",
        "# !pip install transformers datasets torch nltk rouge_score bert-score"
      ],
      "metadata": {
        "id": "ohXEu1XpGIu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install missing packages (optional; uncomment if needed)\n",
        "# !pip install transformers datasets torch nltk rouge_score bert-score matplotlib seaborn pandas numpy\n",
        "\n",
        "# Import remaining libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import nltk\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "from datasets import load_dataset\n",
        "\n",
        "\n",
        "# Set random seeds for reproducibility across libraries\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed_all(42)  # For multi-GPU setups\n",
        "\n",
        "# Suppress FutureWarning for cleaner output\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
      ],
      "metadata": {
        "id": "1KKfc4eqAB9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Notebook configuration"
      ],
      "metadata": {
        "id": "nI9h-VLA_fCc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Log notebook execution timestamp\n",
        "print(f\"Notebook executed on: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
      ],
      "metadata": {
        "id": "wL1i4UWkGAvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"\\nUsing device: {device}\")\n",
        "\n",
        "# Usage note\n",
        "print(\"\"\"\n",
        "=== Usage Note ===\n",
        "Run all cells sequentially. Expected runtime is ~2-3 hours on a T4 GPU.\n",
        "Outputs (models, results) are saved to Google Drive at {BASE_DIR}.\n",
        "Ensure sufficient storage (~5 GB) and a stable connection.\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "ZsDGrQYuCTIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive for persistent storage\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "slMsNieyCLM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# Define base directory in Google Drive\n",
        "BASE_DIR = \"/content/drive/MyDrive/NeurIPS2025_Results\"\n",
        "for subdir in [\"models\", \"qualitative_analysis\"]:\n",
        "    os.makedirs(os.path.join(BASE_DIR, subdir), exist_ok=True)\n",
        "\n",
        "# Function to print GPU memory usage\n",
        "def print_gpu_memory() -> None:\n",
        "    \"\"\"Print current GPU memory usage in GiB.\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        allocated = torch.cuda.memory_allocated() / 1024**3\n",
        "        reserved = torch.cuda.memory_reserved() / 1024**3\n",
        "        print(f\"GPU Memory - Allocated: {allocated:.2f} GiB, Reserved: {reserved:.2f} GiB\")"
      ],
      "metadata": {
        "id": "jwfI_M_y_dLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Load model"
      ],
      "metadata": {
        "id": "B7jVQOqB_kE2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load T5-base model and tokenizer\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\", torch_dtype=torch.float32).to(device)\n",
        "\n",
        "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")\n",
        "train_articles = dataset['train']['article'][:1200]  # 400 training samples\n",
        "train_summaries = dataset['train']['highlights'][:1200]\n",
        "test_articles = dataset['test']['article'][:300]  # 100 test samples\n",
        "test_summaries = dataset['test']['highlights'][:300]"
      ],
      "metadata": {
        "id": "vnjfoj26wMk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Functions"
      ],
      "metadata": {
        "id": "apM6wupY_ywv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def perturb_model(\n",
        "    model: T5ForConditionalGeneration,\n",
        "    articles: List[str],\n",
        "    summaries: List[str],\n",
        "    learning_rate: float,\n",
        "    epochs: int = 3,\n",
        "    accum_steps: int = 4\n",
        ") -> None:\n",
        "    \"\"\"Fine-tune the model on a batch of articles and summaries using APE perturbation.\"\"\"\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "    model.train()\n",
        "\n",
        "    print(\"Before fine-tuning:\")\n",
        "    print_gpu_memory()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        raw_loss = 0\n",
        "        for i, (article, summary) in enumerate(zip(articles, summaries)):\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            inputs = tokenizer(\n",
        "                article, return_tensors=\"pt\", max_length=512,\n",
        "                truncation=True, padding=True\n",
        "            ).to(device)\n",
        "            targets = tokenizer(\n",
        "                summary, return_tensors=\"pt\", max_length=128,\n",
        "                truncation=True, padding=True\n",
        "            ).to(device)\n",
        "\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                outputs = model(\n",
        "                    input_ids=inputs.input_ids,\n",
        "                    attention_mask=inputs.attention_mask,\n",
        "                    labels=targets.input_ids\n",
        "                )\n",
        "                loss = outputs.loss / accum_steps\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            raw_loss += loss.item()\n",
        "\n",
        "            if (i + 1) % accum_steps == 0 or (i + 1) == len(articles):\n",
        "                scaler.unscale_(optimizer)\n",
        "                grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "                print(f\"Epoch {epoch+1}, Step {i+1}: Loss = {raw_loss:.4f}, Grad Norm = {grad_norm:.4f}\")\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                optimizer.zero_grad(set_to_none=True)\n",
        "                raw_loss = 0\n",
        "\n",
        "    print(\"After fine-tuning:\")\n",
        "    print_gpu_memory()\n",
        "\n",
        "def generate_summary(model: T5ForConditionalGeneration, article: str) -> str:\n",
        "    \"\"\"Generate a summary for a given article using the model.\"\"\"\n",
        "    model.eval()\n",
        "    inputs = tokenizer(\n",
        "        article, return_tensors=\"pt\", max_length=512,\n",
        "        truncation=True, padding=True\n",
        "    ).to(device)\n",
        "    with torch.no_grad():\n",
        "        with torch.amp.autocast('cuda'):\n",
        "            outputs = model.generate(\n",
        "                input_ids=inputs.input_ids,\n",
        "                attention_mask=inputs.attention_mask,\n",
        "                max_length=128\n",
        "            )\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
      ],
      "metadata": {
        "id": "uqXBFJnhxRL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Generate summaries"
      ],
      "metadata": {
        "id": "7UolJ1h_A2fM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the baseline model (initial T5-base) to Google Drive\n",
        "model.save_pretrained(os.path.join(GDRIVE_BASE_DIR, \"models/baseline_model\"))\n",
        "tokenizer.save_pretrained(os.path.join(GDRIVE_BASE_DIR, \"models/baseline_model\"))"
      ],
      "metadata": {
        "id": "X4FumJfiyTdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate baseline summaries for qualitative analysis (100 articles)\n",
        "subset_size = 100\n",
        "subset_indices = np.random.choice(len(test_articles), subset_size, replace=False)\n",
        "subset_articles = [test_articles[i] for i in subset_indices]\n",
        "subset_references = [test_summaries[i] for i in subset_indices]\n",
        "\n",
        "baseline_summaries = [generate_summary(model, article) for article in subset_articles]\n",
        "print(f\"Generated {len(baseline_summaries)} baseline summaries.\")\n",
        "\n",
        "# Run APE perturbations (15 iterations, 80 articles per batch)\n",
        "fixed_lr = 3e-6\n",
        "batch_size = 80  # 1,200 articles / 15 iterations ≈ 80\n",
        "perturbations = [\n",
        "    (train_articles[i:i + batch_size], train_summaries[i:i + batch_size], fixed_lr)\n",
        "    for i in range(0, len(train_articles), batch_size)\n",
        "]\n",
        "\n",
        "for i, (articles, summaries, lr) in enumerate(perturbations, 1):\n",
        "    print(f\"Iteration {i}: Perturbing with lr={lr}, {len(articles)} articles\")\n",
        "    perturb_model(model, articles, summaries, lr)\n",
        "\n",
        "# Save final model\n",
        "model.save_pretrained(os.path.join(BASE_DIR, \"models/final_model\"))\n",
        "tokenizer.save_pretrained(os.path.join(BASE_DIR, \"models/final_model\"))\n",
        "print(\"Final model saved.\")\n",
        "\n",
        "# Generate final summaries\n",
        "final_summaries = [generate_summary(model, article) for article in subset_articles]\n",
        "print(f\"Generated {len(final_summaries)} final summaries.\")\n",
        "\n",
        "# Compile qualitative results\n",
        "qualitative_results = [\n",
        "    {\n",
        "        \"article\": article,\n",
        "        \"reference_summary\": ref,\n",
        "        \"baseline_summary\": baseline,\n",
        "        \"final_summary\": final\n",
        "    }\n",
        "    for article, ref, baseline, final in zip(\n",
        "        subset_articles, subset_references, baseline_summaries, final_summaries\n",
        "    )\n",
        "]\n",
        "\n",
        "# Save qualitative results\n",
        "with open(os.path.join(BASE_DIR, \"qualitative_analysis/results.pkl\"), \"wb\") as f:\n",
        "    pickle.dump(qualitative_results, f)\n",
        "print(\"Qualitative results saved.\")\n",
        "\n",
        "# Display example summaries for paper\n",
        "print(\"\\nQualitative Analysis Examples:\")\n",
        "for i, result in enumerate(qualitative_results[:3], 1):\n",
        "    print(f\"\\nExample {i}:\")\n",
        "    print(f\"Article (excerpt): {result['article'][:200]}...\")\n",
        "    print(f\"Reference Summary: {result['reference_summary']}\")\n",
        "    print(f\"Baseline Summary: {result['baseline_summary']}\")\n",
        "    print(f\"Final Summary: {result['final_summary']}\")\n",
        "\n",
        "# Save summaries for human evaluation\n",
        "file_path = os.path.join(BASE_DIR, \"summaries_for_evaluation.txt\")\n",
        "with open(file_path, 'w') as f:\n",
        "    f.write(\"Human Evaluation Texts for Summarization Experiment\\n\")\n",
        "    f.write(\"================================================\\n\\n\")\n",
        "    f.write(\"Instructions: Rate Baseline and Final summaries (1-5) for Informativeness, Fluency, Factual Accuracy.\\n\\n\")\n",
        "    for idx, result in enumerate(qualitative_results, 1):\n",
        "        title = result['article'].split('(CNN)')[1].split('.')[0].strip()[:50]\n",
        "        f.write(f\"Example {idx}: {title}\\n\")\n",
        "        f.write(f\"Article (excerpt): {result['article'][:200]}...\\n\")\n",
        "        f.write(f\"Reference Summary: {result['reference_summary']}\\n\")\n",
        "        f.write(f\"Baseline Summary: {result['baseline_summary']}\\n\")\n",
        "        f.write(f\"Final Summary: {result['final_summary']}\\n\\n\")\n",
        "print(f\"Summaries for evaluation saved to {file_path}\")\n"
      ],
      "metadata": {
        "id": "nWndKCJWyYS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flush and unmount Google Drive\n",
        "drive.flush_and_unmount()\n",
        "print(f\"All results saved to {BASE_DIR}\")\n"
      ],
      "metadata": {
        "id": "tkJLz0vJBuaU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}